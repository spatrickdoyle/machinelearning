{
 "metadata": {
  "name": "",
  "signature": "sha256:32fb636e36eb9c1c074e3c026ba8f83143ddff28b1aada69ad286e276c7a6bff"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basic logistic regression model with L1 regularization for promoter enhancer predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import timeit\n",
      "import numpy as np\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "\n",
      "BASE_PATH = './' # path to directory with data for enhancer/promoter prediction project"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "define helper function to convert string labels to integers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def labelstr2labelint(labelstr):   \n",
      "    labels= ['EnhancerInactive+PromoterInactive+Exon+Unknown', 'PromoterActive', 'EnhancerActive']\n",
      "    \n",
      "    return labels.index(labelstr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = np.loadtxt(BASE_PATH + './GM12878_200bp_Data_3Cl_l2normalized_TrainSet.txt')\n",
      "X_valid = np.loadtxt(BASE_PATH + 'GM12878_200bp_Data_3Cl_l2normalized_ValidSet.txt')\n",
      "X_test = np.loadtxt(BASE_PATH + 'GM12878_200bp_Data_3Cl_l2normalized_TestSet.txt')\n",
      "\n",
      "y_train = np.loadtxt(BASE_PATH + 'GM12878_200bp_Classes_3Cl_l2normalized_TrainSet.txt', converters = {0: labelstr2labelint})\n",
      "y_valid = np.loadtxt(BASE_PATH + 'GM12878_200bp_Classes_3Cl_l2normalized_ValidSet.txt', converters = {0: labelstr2labelint})\n",
      "y_test = np.loadtxt(BASE_PATH + 'GM12878_200bp_Classes_3Cl_l2normalized_TestSet.txt', converters = {0: labelstr2labelint})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'shape of our feature matrix: ', np.shape(X_train)\n",
      "print 'set of labels: ', set(y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "shape of our feature matrix:  (2156, 93)\n",
        "set of labels:  set([0.0, 1.0, 2.0])\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Concatenate training and validation data for cross-validated search over hyper parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_valid = np.row_stack((X_train, X_valid))\n",
      "y_train_valid = np.concatenate((y_train, y_valid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next\n",
      "\n",
      "    define range of values for L1 penalty\n",
      "    evaluate hyper parameters using a grid search with 3-fold cross-validation\n",
      "    choose hyper parameters with best accuracy across the folds\n",
      "    refit model with optimal hyper parameters on the entire training+validation data\n",
      "    parallelize across 4 processors using scikit's GridSearchCV\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = timeit.default_timer()\n",
      "\n",
      "tuned_parameters = [{'C': [0.1, 0.3, 1, 2, 3, 4, 5, 10, 30, 100]}]\n",
      "clf = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, cv=3,\n",
      "                   n_jobs=4, scoring='accuracy')\n",
      "clf.fit(X_train_valid, y_train_valid)\n",
      "\n",
      "stop = timeit.default_timer()\n",
      "print 'Grid search runtime: ', stop - start "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Grid search runtime:  8.2408349514\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Print\n",
      "\n",
      "    best L1 penalty\n",
      "    validation accuracy +/- standard error across cross validation folds for different L1 penalties\n",
      "    test accuracy\n",
      "    confusion matrix for the test predictions\n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Best parameters set found on development set:\")\n",
      "print(clf.best_params_)\n",
      "print(\"Grid scores on development set:\")\n",
      "for params, mean_score, scores in clf.grid_scores_:\n",
      "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "            % (mean_score, scores.std() * 2, params))\n",
      "print(\"printing test results...\")\n",
      "y_true, y_pred = y_test, clf.predict(X_test)\n",
      "print('Test Accuracy:')\n",
      "print(accuracy_score(y_true, y_pred))\n",
      "print ('Test Confusion Matrix:')\n",
      "print(confusion_matrix(y_true, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best parameters set found on development set:\n",
        "{'C': 5}\n",
        "Grid scores on development set:\n",
        "0.870 (+/-0.008) for {'C': 0.1}\n",
        "0.885 (+/-0.015) for {'C': 0.3}\n",
        "0.896 (+/-0.014) for {'C': 1}\n",
        "0.896 (+/-0.012) for {'C': 2}\n",
        "0.897 (+/-0.010) for {'C': 3}\n",
        "0.899 (+/-0.010) for {'C': 4}\n",
        "0.899 (+/-0.011) for {'C': 5}\n",
        "0.896 (+/-0.013) for {'C': 10}\n",
        "0.896 (+/-0.014) for {'C': 30}\n",
        "0.896 (+/-0.014) for {'C': 100}\n",
        "printing test results...\n",
        "Test Accuracy:\n",
        "0.894248608534\n",
        "Test Confusion Matrix:\n",
        "[[645  35  39]\n",
        " [ 11 659  49]\n",
        " [ 32  62 624]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "89%-90% is the published performance "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}